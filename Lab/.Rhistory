for(i_BT in 1:B){
X_BT = rnorm(n, mean=X_mean, sd=X_sd)
X_med_BT[i_BT] = median(X_BT)
}
hist(X_med_BT, col="violet")
abline(v= X_med, col="blue", lwd=6)
n
length(X)
B = 10000
X_med_BT = rep(NA, B)
for(i_BT in 1:B){
X_BT = rnorm(length(X), mean=X_mean, sd=X_sd)
X_med_BT[i_BT] = median(X_BT)
}
hist(X_med_BT, col="violet")
abline(v= X_med, col="blue", lwd=6)
#### Exercise 2:
#### In this exercise, we will use the 'rock' data, a built-in dataset in R.
head(rock)
#### We focus on the variable 'area'; here is the histogram:
hist(rock$area, col="aquamarine")
area_mean <- mean(rock$area)
sd(rock$area)
area_sd(rock$area)
area_sd <- sd(rock$area)
sp_dt <- rnorm(length(rock$area), area_mean, area_sd)
area_med <- median(rock$area)
sample_med <- rep(NA, B)
for (ii in 1:B) {
sp_dt <- rnorm(length(rock$area), area_mean, area_sd)
sample_med[ii] <- median(sp_dt)
}
hist(sample_med)
abline(v=area_med)
hist(rock$area)
abline(area_med)
abline(v=area_med)
sample_med <- rep(NA, B)
for (ii in 1:B) {
sp_dt <- rnorm(length(rock$area), area_mean, area_sd)
sample_med[ii] <- median(sp_dt)
}
hist(sample_med)
abline(v=area_med)
###                          ###
### Part 3: Permutation Test ###
###                          ###
data0$Sex
dataM = data0$`Whole weight`[data0$Sex=="M"]
dataF = data0$`Whole weight`[data0$Sex=="F"]
t.test(dataM, dataF)
ks.test(dataM,dataF)
## permutation test + median
dataM_med = median(dataM)
dataF_med = median(dataF)
diff_med = abs(dataM_med-dataF_med)
diff_med
head(dataF)
head(dataM)
n_M = length(dataM)
n_F = length(dataF)
n = n_M+n_F
data_pull = c(dataM, dataF)
N_per = 10000
diff_med_per = rep(NA, N_per)
for(i_per in 1:N_per){
w_per = sample(n, n, replace=F)
data_per = data_pull[w_per]
# data after permutation
dataM_new = data_per[1:n_M]
dataF_new = data_per[(n_M+1):n]
# first n_M are new group M; the others are new group F
diff_new = abs(median(dataM_new)-median(dataF_new))
# compute the difference
diff_med_per[i_per] = diff_new
}
which(diff_med_per>diff_med)
length(which(diff_med_per>diff_med))/N_per
## permutation test + 10% quantile
dataM_q1 = quantile(dataM,0.1)
dataF_q1 = quantile(dataF,0.1)
diff_q1 = abs(dataM_q1-dataF_q1)
hist(diff_med_per)
abline(v=diff_med)
weightF <- data0$`Whole weight`[data0$Sex=='F']
weightM <- data0$`Whole weight`[data0$Sex=='M']
t.test(weightF, weightM)
ks.test(weightF, weightM)
weightc <- c(weightF, weightM)
n_M <- length(weightM)
n_F <- length(weightF)
n <- length(weightF) + length(weightM)
diff_med_per <- rep(NA, N_per)
for (ii in 1:N_per) {
w_per = sample(n, n, replace=F)
data_per = weightc[w_per]
dataM_new = data_per[1:n_M]
dataF_new = data_per[(n_M+1):n]
diff_new = abs(quantile(dataM_new,0.1)-quantile(dataF_new,0.1))
# now we use 10% quantile difference
diff_med_per[ii] = diff_new
}
hist(diff_med_per)
diff_med <- median(weightM) - median(weightF)
which(diff_med_per > diff_med)
which(diff_med_per < diff_med)
diff_med <- median(weightM) - median(weightF)
diff_med
which(diff_med_per > abs(diff_med)) / N_per
wlength(hich(diff_med_per > abs(diff_med))) / N_per
length(hich(diff_med_per > abs(diff_med))) / N_per
length(which(diff_med_per > abs(diff_med))) / N_per
for (ii in 1:N_per) {
w_per = sample(n, n, replace=F)
data_per = weightc[w_per]
dataM_new = data_per[1:n_M]
dataF_new = data_per[(n_M+1):n]
diff_new = abs(median(dataM_new)-median(dataF_new))
# now we use 10% quantile difference
diff_med_per[ii] = diff_new
}
length(which(diff_med_per > abs(diff_med))) / N_per
###                               ###
### Part 4: Bootstrap Convergence ###
###                               ###
## We now will compare the quality of bootstrap estimate.
## We first compute the error of sample median using Monte Carlo Simulation.
n = 1000
X = rnorm(n)
med0 = 0
X_med = median(X)
X_med
N = 10000
# number of Monte Carlo
X_med_MC = rep(NA, N)
for(i_MC in 1:N){
X = rnorm(n)
X_med_MC[i_MC] = median(X)
}
X_med_VAR = var(X_med_MC)
X_med_VAR
X_med_MSE = mean((X_med_MC-med0)^2)
X_med_MSE
## bootstrap case
X = rnorm(n)
# just one sample
X_med = median(X)
X_med
B = 10000
X_med_BT = rep(NA, B)
for(i_BT in 1:B){
w = sample(n,n,replace=T)
X_BT = X[w]
X_med_BT[i_BT] = median(X_BT)
}
X_med_BT_VAR = var(X_med_BT)
X_med_BT_VAR
X_med_BT_MSE = mean((X_med_BT-X_med)^2)
X_med_BT_MSE
X_med_VAR = var(X_med_MC)
X_med_VAR
X_med_MSE
X_med = median(X)
X_med
N = 10000
# number of Monte Carlo
X_med_MC = rep(NA, N)
for(i_MC in 1:N){
X = rnorm(n)
X_med_MC[i_MC] = median(X)
}
X_med_VAR = var(X_med_MC)
X_med_VAR
X_med_MSE = mean((X_med_MC-med0)^2)
mean(X_med_MC)
## bootstrap case
X = rnorm(n)
# just one sample
X_med = median(X)
X_med
B = 10000
X_med_BT = rep(NA, B)
for(i_BT in 1:B){
w = sample(n,n,replace=T)
X_BT = X[w]
X_med_BT[i_BT] = median(X_BT)
}
X_med_BT_VAR = var(X_med_BT)
X_med_BT_VAR
X_med_BT_MSE = mean((X_med_BT-X_med)^2)
X_med_BT_MSE
## comparison
X_med_BT_VAR
X_med_VAR
X_med_BT_MSE
X_med_MSE
### different sample size
N = 10000
B = 10000
n_seq = c(50, 200, 500, 1000, 2000, 5000)
info_matrix = matrix(NA, nrow=length(n_seq), ncol=4)
colnames(info_matrix) = c("VAR","MSE","VAR_BT","MSE_BT")
rownames(info_matrix) = n_seq
info_matrix
for(i_n in 1:length(n_seq)){
n = n_seq[i_n]
X_med_MC = rep(NA, N)
for(i_MC in 1:N){
X = rnorm(n)
X_med_MC[i_MC] = median(X)
}
info_matrix[i_n,1] = var(X_med_MC)
info_matrix[i_n,2] = mean((X_med_MC-med0)^2)
X = rnorm(n)
X_med = median(X)
X_med_BT = rep(NA, B)
for(i_BT in 1:B){
w = sample(n,n,replace=T)
X_BT = X[w]
X_med_BT[i_BT] = median(X_BT)
}
info_matrix[i_n,3] = var(X_med_BT)
info_matrix[i_n,4] = mean((X_med_BT-X_med)^2)
}
info_matrix
plot(NULL, xlim=c(0,5000),ylim=c(0.5, 2.5),
ylab="VAR_BT / VAR", xlab="Sample size", main="Bootstrap VAR")
abline(h=1, lwd=3, col="gray")
points(x=n_seq, y=info_matrix[,3]/info_matrix[,1], pch=20,
col="slateblue", cex=2)
lines(x=n_seq, y=info_matrix[,3]/info_matrix[,1], col="slateblue", lwd=3)
plot(NULL, xlim=c(0,5000),ylim=c(0.5, 2.5),
ylab="MSE_BT / MSE", xlab="Sample size", main="Bootstrap MSE")
abline(h=1, lwd=3, col="gray")
points(x=n_seq, y=info_matrix[,4]/info_matrix[,2], pch=20,
col="palevioletred", cex=2)
lines(x=n_seq, y=info_matrix[,3]/info_matrix[,1], col="palevioletred", lwd=3)
abline(h=1, lwd=3, col="gray")
points(x=n_seq, y=info_matrix[,3]/info_matrix[,1], pch=20,
col="slateblue", cex=2)
plot(NULL, xlim=c(0,5000),ylim=c(0.5, 2.5),
ylab="VAR_BT / VAR", xlab="Sample size", main="Bootstrap VAR")
abline(h=1, lwd=3, col="gray")
points(x=n_seq, y=info_matrix[,3]/info_matrix[,1], pch=20,
col="slateblue", cex=2)
lines(x=n_seq, y=info_matrix[,3]/info_matrix[,1], col="slateblue", lwd=3)
B = 10000
#### For simplicity, we choose Monte Carlo Size N = 10000 and Bootstrap
#### size B = 10000.
N = 10000
IQR
IQR(0.5)
IQR(runif(500), 0.5)
MC_var <- var(interqt_MC)
n <- 500
interqt_MC <- rep(NA, N)
for (ii in 1:N) {
sp <- runif(n)
interqt_MC[ii] <- IQR(sp, IQR0)
}
#### Exercise 4:
#### Mimic the above procedure and generate data from Uni[0,1] to see
#### the convergence of bootstrap VAR and MSE of the sample IQR.
#### In this case, we know that the IQR is 0.50.
IQR0 = 0.50
#### For simplicity, we choose Monte Carlo Size N = 10000 and Bootstrap
#### size B = 10000.
N = 10000
B = 10000
n <- 500
interqt_MC <- rep(NA, N)
for (ii in 1:N) {
sp <- runif(n)
interqt_MC[ii] <- IQR(sp, IQR0)
}
MC_var <- var(interqt_MC)
MC_mse <- mean((interqt_MC - 0.5)^2)
MC_var
MC_mse
X <- runif(n)
x_mde <- IQR(X, 0.5)
x_iqr <- IQR(X, 0.5)
x_iqr
X <- runif(n)
x_iqr <- IQR(X, 0.5)
interqt_BT <- rep(NA, B)
for (ii in 1:B) {
sp <- sample(n, n, replace=T)
sp_dt <- X[sp]
interqt_BT[ii] <- IQR(sp)
}
mean(interqt_BT)
interqt_BT[ii] <- IQR(sp_dt)
X <- runif(n)
x_iqr <- IQR(X, 0.5)
interqt_BT <- rep(NA, B)
for (ii in 1:B) {
sp <- sample(n, n, replace=T)
sp_dt <- X[sp]
interqt_BT[ii] <- IQR(sp_dt)
}
mean(interqt_BT)
BT_mse <- mean((interqt_BT - x_iqr)^2)
BT_var <- var(interqt_BT)
BT_var
x_value <- rnorm(500)
x_value <- rnorm(500)
y_value <- rbinom(n, size=1, p=bern_p(x_value))
# questoin 1-a
bern_p <- function(x) {
return(exp(1 + 2 * x) / (1 + exp(1 + 2 * x)))
}
n <- 500
x_value <- rnorm(500)
y_value <- rbinom(n, size=1, p=bern_p(x_value))
xy_logic = glm(y_value~x_value, family = "binomial")
beta0 <- summary(xy_logic)$coefficient[1,1]
beta1 <- summary(xy_logic)$coefficient[2,1]
beta0
beta1
n <- 500
x_value <- rnorm(500)
y_value <- rbinom(n, size=1, p=bern_p(x_value))
xy_logic = glm(y_value~x_value, family = "binomial")
beta0 <- summary(xy_logic)$coefficient[1,1]
beta1 <- summary(xy_logic)$coefficient[2,1]
beta0
beta1
N = 2000
beta0_sim <- rep(NA, N)
beta1_sim <- rep(NA, N)
for (ii in 1:N) {
x_value <- rnorm(n)
y_value <- rbinom(n, size=1, p=bern_p(x_value))
xy_logic = glm(y_value~x_value, family = "binomial")
beta0_sim[ii] <- summary(xy_logic)$coefficient[1,1]
beta1_sim[ii] <- summary(xy_logic)$coefficient[2,1]
}
hist(beta0_sim, probability=T, main='Histogram of Fitted Beta0', breaks=20,
xlab='Fitted Beta0', col='coral1')
abline(v=1, lwd=3, col='cornflowerblue' )
legend('topright', 'True Beta0', col='cornflowerblue', lwd=3, cex=0.75)
hist(beta1_sim, probability=T, main='Histogram of Fitted Beta1', breaks=20,
xlab='Fitted Beta1', col='cornflowerblue')
abline(v=2, lwd=3, col='coral1' )
legend('topright', 'True Beta1', col='coral1', lwd=3, cex=0.75)
N = 2000
beta0_sim <- rep(NA, N)
beta1_sim <- rep(NA, N)
for (ii in 1:N) {
x_value <- rnorm(n)
y_value <- rbinom(n, size=1, p=bern_p(x_value))
xy_logic = glm(y_value~x_value, family = "binomial")
beta0_sim[ii] <- summary(xy_logic)$coefficient[1,1]
beta1_sim[ii] <- summary(xy_logic)$coefficient[2,1]
}
hist(beta0_sim, probability=T, main='Histogram of Fitted Beta0', breaks=20,
xlab='Fitted Beta0', col='coral1')
abline(v=1, lwd=3, col='cornflowerblue' )
legend('topright', 'True Beta0', col='cornflowerblue', lwd=3, cex=0.75)
hist(beta1_sim, probability=T, main='Histogram of Fitted Beta1', breaks=20,
xlab='Fitted Beta1', col='cornflowerblue')
abline(v=2, lwd=3, col='coral1' )
legend('topright', 'True Beta1', col='coral1', lwd=3, cex=0.75)
n <- 500
x_value <- rnorm(500)
y_value <- rbinom(n, size=1, p=bern_p(x_value))
xy_logic = glm(y_value~x_value, family = "binomial")
beta0 <- summary(xy_logic)$coefficient[1,1]
beta1 <- summary(xy_logic)$coefficient[2,1]
beta0
beta1
n <- 500
x_value <- rnorm(500)
y_value <- rbinom(n, size=1, p=bern_p(x_value))
xy_logic = glm(y_value~x_value, family = "binomial")
beta0 <- summary(xy_logic)$coefficient[1,1]
beta1 <- summary(xy_logic)$coefficient[2,1]
beta0
beta1
n <- 500
x_value <- rnorm(500)
y_value <- rbinom(n, size=1, p=bern_p(x_value))
xy_logic = glm(y_value~x_value, family = "binomial")
beta0 <- summary(xy_logic)$coefficient[1,1]
beta1 <- summary(xy_logic)$coefficient[2,1]
beta0
beta1
N = 2000
beta0_sim <- rep(NA, N)
beta1_sim <- rep(NA, N)
for (ii in 1:N) {
x_value <- rnorm(n)
y_value <- rbinom(n, size=1, p=bern_p(x_value))
xy_logic = glm(y_value~x_value, family = "binomial")
beta0_sim[ii] <- summary(xy_logic)$coefficient[1,1]
beta1_sim[ii] <- summary(xy_logic)$coefficient[2,1]
}
hist(beta0_sim, probability=T, main='Histogram of Fitted Beta0', breaks=20,
xlab='Fitted Beta0', col='coral1')
abline(v=1, lwd=3, col='cornflowerblue' )
legend('topright', 'True Beta0', col='cornflowerblue', lwd=3, cex=0.75)
hist(beta1_sim, probability=T, main='Histogram of Fitted Beta1', breaks=20,
xlab='Fitted Beta1', col='cornflowerblue')
abline(v=2, lwd=3, col='coral1' )
legend('topright', 'True Beta1', col='coral1', lwd=3, cex=0.75)
# question 1-d
n = 2000
N = 2000
beta0_sim <- rep(NA, N)
beta1_sim <- rep(NA, N)
for (ii in 1:N) {
x_value <- rnorm(n)
y_value <- rbinom(n, size=1, p=bern_p(x_value))
xy_logic = glm(y_value~x_value, family = "binomial")
beta0_sim[ii] <- summary(xy_logic)$coefficient[1,1]
beta1_sim[ii] <- summary(xy_logic)$coefficient[2,1]
}
hist(beta0_sim, probability=T, main='Histogram of Fitted Beta0', breaks=20,
xlab='Fitted Beta0', col='coral1', xlim=c(0.2, 1.8))
abline(v=1, lwd=3, col='cornflowerblue' )
legend('topright', 'True Beta0', col='cornflowerblue', lwd=3, cex=0.75)
hist(beta0_sim, probability=T, main='Histogram of Fitted Beta0', breaks=20,
xlab='Fitted Beta0', col='coral1', xlim=c(0.5, 1.5))
abline(v=1, lwd=3, col='cornflowerblue' )
legend('topright', 'True Beta0', col='cornflowerblue', lwd=3, cex=0.75)
hist(beta1_sim, probability=T, main='Histogram of Fitted Beta1', breaks=20,
xlab='Fitted Beta1', col='cornflowerblue', xlim=c(0.5, 4.0))
abline(v=2, lwd=3, col='coral1' )
xlab='Fitted Beta1', col='cornflowerblue', xlim=c(1, 3)
hist(beta1_sim, probability=T, main='Histogram of Fitted Beta1', breaks=20,
xlab='Fitted Beta1', col='cornflowerblue', xlim=c(1, 3))
hist(beta1_sim, probability=T, main='Histogram of Fitted Beta1', breaks=20,
xlab='Fitted Beta1', col='cornflowerblue', xlim=c(1.5, 3.5))
hist(beta1_sim, probability=T, main='Histogram of Fitted Beta1', breaks=20,
xlab='Fitted Beta1', col='cornflowerblue', xlim=c(1.5, 2.5))
hist(beta1_sim, probability=T, main='Histogram of Fitted Beta1', breaks=20,
xlab='Fitted Beta1', col='cornflowerblue', xlim=c(1, 3))
abline(v=2, lwd=3, col='coral1' )
legend('topright', 'True Beta1', col='coral1', lwd=3, cex=0.75)
hist(beta1_sim, probability=T, main='Histogram of Fitted Beta1', breaks=20,
xlab='Fitted Beta1', col='cornflowerblue', xlim=c(1, 3))
abline(v=2, lwd=3, col='coral1' )
library(Metrics)
sample_sizes <- seq(from=100, to=2000, by=200)
beta1_mse <- rep(NA, length(sample_sizes))
N = 2000
for (ii in 1:length(sample_sizes)) {
n <- sample_sizes[ii]
beta1 <- rep(NA, N)
for (jj in 1:N) {
x_value <- rnorm(n)
y_value <- rbinom(n, size=1, p=bern_p(x_value))
xy_logic = glm(y_value~x_value, family = "binomial")
beta1[jj] <- summary(xy_logic)$coefficient[2,1]
}
beta1_mse[ii] <- mse(beta1, 2)
}
plot(x=sample_sizes, y=beta1_mse, type='ln', lwd=3, col='coral1', xlim=c(100, 2000),
xlab='Sample Size', ylab='MSE of Estimated Beta1',
main='MSE of Estimated Beta1 VS Sample Size')
points(x=sample_sizes, y=beta1_mse, pch=20, cex=2, col="skyblue")
grid(nx=NA,ny=NULL,lty=1,lwd=0.5,col="gray")
1/1.7
# question 2-c
density_func <- function(x) {
return(exp(x)/(1 + exp(x))^2)
}
M = 1.7
sim_size <- 20000
sim_U <- runif(sim_size, 20000)
sim_U <- runif(sim_size)
sim_Y <- rcauchy(sim_size, 0, 1)
sim_X <- sim_Y[which(sim_U < density_func(Y) / (M * dcauchy(Y)))]
sim_X <- sim_Y[which(sim_U < density_func(sim_Y) / (M * dcauchy(sim_Y)))]
length(sim_X)
hist(sim_X)
hist(sim_X, breaks=30)
hist(sim_X, breaks=30, xlim=c(-10,10))
lines(x_base, density_value)
x_base <- seq(-10, 10, 0.01)
density_value <- density_func(x_base)
lines(x_base, density_value)
hist(sim_X, breaks=30, probability=T, xlim=c(-10,10))
lines(x_base, density_value)
hist(sim_X, breaks=30, probability=T, xlim=c(-10,10), ylim=c(0, 0.25))
hist(sim_X, breaks=30, probability=T, xlim=c(-10,10), ylim=c(0, 0.25),
xlab='X', main='Histogram of X', col='coral1')
lines(x_base, density_value, lwd=3, col='skyblue')
hist(sim_X, breaks=30, probability=T, xlim=c(-10,10), ylim=c(0, 0.25),
xlab='X', main='Histogram of X', col='skyblue')
lines(x_base, density_value, lwd=3, col='coral1')
hist(sim_X, breaks=30, probability=T, xlim=c(-10,10), ylim=c(0, 0.25),
xlab='X', main='Histogram of X', col='coral')
lines(x_base, density_value, lwd=3, col='skyblue')
hist(sim_X, breaks=30, probability=T, xlim=c(-10,10), ylim=c(0, 0.25),
xlab='X', main='Histogram of X', col='coral1')
lines(x_base, density_value, lwd=3, col='skyblue')
legend('topright', col='skyblue', 'True Density', wed=3)
?legend
legend('topright', col='skyblue', legend='True Density', wed=3)
legend('topright', col='skyblue', legend='True Density', lwd=3)
legend('topright', col='skyblue', legend='True Density', lwd=3, cex=0.8)
hist(sim_X, breaks=30, probability=T, xlim=c(-10,10), ylim=c(0, 0.25),
xlab='X', main='Histogram of X', col='coral1')
lines(x_base, density_value, lwd=3, col='skyblue')
legend('topright', col='skyblue', legend='True Density', lwd=3, cex=0.8)
legend('topright', col='skyblue', legend='True Density', lwd=3, cex=0.75)
hist(sim_X, breaks=30, probability=T, xlim=c(-10,10), ylim=c(0, 0.25),
xlab='X', main='Histogram of X', col='coral1')
lines(x_base, density_value, lwd=3, col='skyblue')
legend('topright', col='skyblue', legend='True Density', lwd=3, cex=0.75)
